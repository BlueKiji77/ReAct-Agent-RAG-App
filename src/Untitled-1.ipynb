{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 98\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m cl\u001b[38;5;241m.\u001b[39mMessage(\n\u001b[1;32m     94\u001b[0m             content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ An error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         )\u001b[38;5;241m.\u001b[39msend()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mcl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/chainlit/utils.py:70\u001b[0m, in \u001b[0;36mmake_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m---> 70\u001b[0m     module_path \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     71\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(module_path, __package__)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'run'"
     ]
    }
   ],
   "source": [
    "import chainlit as cl\n",
    "from llama_deploy import LlamaDeployClient, ControlPlaneConfig#, SessionClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get configuration from environment variables\n",
    "CONTROL_PLANE_HOST = \"localhost\"\n",
    "CONTROL_PLANE_PORT = 8000\n",
    "WORKFLOW_NAME = \"react_workflow\"\n",
    "\n",
    "if not all([CONTROL_PLANE_HOST, WORKFLOW_NAME]):\n",
    "    raise ValueError(\"Missing required environment variables. Please check your .env file.\")\n",
    "\n",
    "# Create a LlamaDeployClient instance\n",
    "client = LlamaDeployClient(\n",
    "    ControlPlaneConfig(\n",
    "        host=CONTROL_PLANE_HOST,\n",
    "        port=CONTROL_PLANE_PORT\n",
    "    )\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def start():\n",
    "    \"\"\"Initialize the chat session.\"\"\"\n",
    "    # Create a SessionClient instance and store it in the user session\n",
    "    session = client.create_session()\n",
    "    cl.user_session.set(\"llama_session\", session)\n",
    "    \n",
    "    await cl.Message(\n",
    "        content=\"ðŸ‘‹ Hello! I'm your AI assistant powered by LlamaIndex. I can help you analyze \"\n",
    "        \"Uber and Lyft's financial data from their 2021 10-K reports. What would you like to know?\"\n",
    "    ).send()\n",
    "\n",
    "@cl.on_message\n",
    "async def main(message: cl.Message):\n",
    "    \"\"\"Handle incoming messages.\"\"\"\n",
    "    try:\n",
    "        # Get the SessionClient instance from the user session\n",
    "        session = cl.user_session.get(\"llama_session\")\n",
    "        if not session:\n",
    "            # If session is not found, create a new one\n",
    "            session = client.create_session()\n",
    "            cl.user_session.set(\"llama_session\", session)\n",
    "\n",
    "        # Create a thinking message\n",
    "        thinking_msg = cl.Message(content=\"Thinking...\")\n",
    "        await thinking_msg.send()\n",
    "\n",
    "        # Run the workflow and get the task result\n",
    "        result = session.run(\n",
    "            WORKFLOW_NAME,\n",
    "            input=message.content\n",
    "        )\n",
    "\n",
    "        # Extract the response and sources\n",
    "        print(f\"result:{result}\")\n",
    "        final_response = result.get(\"response\", \"No response generated\")\n",
    "        sources = result.get(\"sources\", [])\n",
    "\n",
    "        # Create elements for the final message\n",
    "        elements = []\n",
    "        if result.get(\"current_reasoning\"):\n",
    "            reasoning_text = \"\\n\".join(\n",
    "                f\"{step_num}. Thought: {step.thought}\\nAction: {step.action}\\nObservation: {step.observation}\"\n",
    "                for step_num, step in enumerate(result[\"current_reasoning\"], 1)\n",
    "            )\n",
    "            elements.append(\n",
    "                cl.Text(name=\"reasoning\", content=reasoning_text, display=\"inline\")\n",
    "            )\n",
    "        \n",
    "        if sources:\n",
    "            source_text = \"\\nSources:\\n\" + \"\\n\".join(\n",
    "                [f\"- {source}\" for source in sources]\n",
    "            )\n",
    "            elements.append(\n",
    "                cl.Text(name=\"sources\", content=source_text, display=\"inline\")\n",
    "            )\n",
    "\n",
    "        # Send the final response\n",
    "        await cl.Message(\n",
    "            content=final_response,\n",
    "            elements=elements\n",
    "        ).send()\n",
    "\n",
    "        # Remove the thinking message\n",
    "        await thinking_msg.remove()\n",
    "\n",
    "    except Exception as e:\n",
    "        # Send error message\n",
    "        await cl.Message(\n",
    "            content=f\"âŒ An error occurred: {str(e)}\"\n",
    "        ).send()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mcl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/chainlit/utils.py:70\u001b[0m, in \u001b[0;36mmake_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m---> 70\u001b[0m     module_path \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     71\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(module_path, __package__)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'run'"
     ]
    }
   ],
   "source": [
    "import chainlit as cl\n",
    "from llama_deploy import LlamaDeployClient, ControlPlaneConfig#, SessionClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get configuration from environment variables\n",
    "CONTROL_PLANE_HOST = \"localhost\"\n",
    "CONTROL_PLANE_PORT = 8000\n",
    "WORKFLOW_NAME = \"react_workflow\"\n",
    "\n",
    "if not all([CONTROL_PLANE_HOST, WORKFLOW_NAME]):\n",
    "    raise ValueError(\"Missing required environment variables. Please check your .env file.\")\n",
    "\n",
    "# Create a LlamaDeployClient instance\n",
    "client = LlamaDeployClient(\n",
    "    ControlPlaneConfig(\n",
    "        host=CONTROL_PLANE_HOST,\n",
    "        port=CONTROL_PLANE_PORT\n",
    "    )\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def start():\n",
    "    \"\"\"Initialize the chat session.\"\"\"\n",
    "    # Create a SessionClient instance and store it in the user session\n",
    "    session = client.create_session()\n",
    "    cl.user_session.set(\"llama_session\", session)\n",
    "    \n",
    "    await cl.Message(\n",
    "        content=\"ðŸ‘‹ Hello! I'm your AI assistant powered by LlamaIndex. I can help you analyze \"\n",
    "        \"Uber and Lyft's financial data from their 2021 10-K reports. What would you like to know?\"\n",
    "    ).send()\n",
    "\n",
    "@cl.on_message\n",
    "async def main(message: cl.Message={'role': 'user', 'content': 'Hello'}):\n",
    "    \"\"\"Handle incoming messages.\"\"\"\n",
    "    # Get the SessionClient instance from the user session\n",
    "    session = cl.user_session.get(\"llama_session\")\n",
    "    if not session:\n",
    "        # If session is not found, create a new one\n",
    "        session = client.create_session()\n",
    "        cl.user_session.set(\"llama_session\", session)\n",
    "\n",
    "    # Create a thinking message\n",
    "    thinking_msg = cl.Message(content=\"Thinking...\")\n",
    "    await thinking_msg.send()\n",
    "\n",
    "    # Run the workflow and get the task result\n",
    "    result = session.run(\n",
    "        WORKFLOW_NAME,\n",
    "        input=message.content\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
